{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, PreTrainedTokenizerFast, GPT2LMHeadModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(\"/root/CS408-Team-2/model/run/\", local_files_only = True)\n",
    "        self.tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "            bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "            pad_token='<pad>', mask_token='<mask>')\n",
    "\n",
    "\n",
    "    def generate(self, inp, context):\n",
    "        estimated_num_tokens = len(inp.split(' '))\n",
    "        if estimated_num_tokens > 50:\n",
    "            inp = \" \".join(inp.split(' ')[-50:])\n",
    "        else:\n",
    "            inp = context[max(-(50-estimated_num_tokens), -len(context)+1):] + inp\n",
    "        print(inp)\n",
    "        out = self.forward(inp)\n",
    "\n",
    "        end_out = max([out.rfind('.'), out.rfind('!'), out.rfind('?')])\n",
    "        out = out[len(inp)+1:end_out+1]\n",
    "        context = context + inp + out\n",
    "        if len(context) > 1000: context = context[-1000:]\n",
    "        return out, context\n",
    "\n",
    "    def forward(self, inp):\n",
    "        input_ids = self.tokenizer.encode(inp)\n",
    "        gen_ids = self.model.generate(torch.tensor([input_ids]),\n",
    "            max_length=128,\n",
    "            repetition_penalty=2.0,\n",
    "            pad_token_id=self.tokenizer.pad_token_id,\n",
    "            eos_token_id=self.tokenizer.eos_token_id,\n",
    "            bos_token_id=self.tokenizer.bos_token_id,\n",
    "            use_cache=True)\n",
    "        out = self.tokenizer.decode(gen_ids[0,:].tolist())\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그 날 밤은 유난히도 추웠다.\n",
      "그러나 그날 밤의 일은 너무나 평화스러워서 견딜 수가 없었다. 나는 잠이 오지 않았다. 그리고 다음날 아침에는 다시 잠을 청했다. 그런데 이상한 일이 일어났다! 그것은 바로 내가 누워 있는 침대 위에 누운 채였다. 이게 무슨 짓이야? 하고 그는 소리쳤지만 아무도 대답하지 못하였다. 그래서 난로 옆에 가서 불을 켜고 잤는데 갑자기 꿈속에서 일어난 일이었다. 꿈을 꾸는 동안에도 그의 얼굴은 창백해졌다. 하지만 그가 깨어나자 이내 눈에서는 빛났고, 또 눈을 뜨면 눈이 밝아지는 것이었다. 마치 한 마리의 새가 날개를 퍼덕이며 날아가는 것 같았다.\n",
      "그 날 밤은 유난히도 추웠다.그러나 그날 밤의 일은 너무나 평화스러워서 견딜 수가 없었다. 나는 잠이 오지 않았다. 그리고 다음날 아침에는 다시 잠을 청했다. 그런데 이상한 일이 일어났다! 그것은 바로 내가 누워 있는 침대 위에 누운 채였다. 이게 무슨 짓이야? 하고 그는 소리쳤지만 아무도 대답하지 못하였다. 그래서 난로 옆에 가서 불을 켜고 잤는데 갑자기 꿈속에서 일어난 일이었다. 꿈을 꾸는 동안에도 그의 얼굴은 창백해졌다. 하지만 그가 깨어나자 이내 눈에서는 빛났고, 또 눈을 뜨면 눈이 밝아지는 것이었다. 마치 한 마리의 새가 날개를 퍼덕이며 날아가는 것 같았다.\n"
     ]
    }
   ],
   "source": [
    "inp = \"그 날 밤은 유난히도 추웠다.\"\n",
    "\n",
    "inp = \" \".join(inp.split(' ')[-50:])\n",
    "out, context = model.generate(inp, \"\")\n",
    "print(out)\n",
    "print(context)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b466ecc5d6b88f80921b959cfb048696eae6dcc39f562774ffb4576d926d47c4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
